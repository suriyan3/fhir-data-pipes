{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e49f36",
   "metadata": {},
   "source": [
    "# Steps to run expressions on sql table using python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d2388",
   "metadata": {},
   "source": [
    "## 1. We run the pipeline to generate the parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3df806",
   "metadata": {},
   "source": [
    "## 2. Spark client setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8eedf3",
   "metadata": {},
   "source": [
    "The cell below sets up the Spark client and creates a new dataset that will be used for this analysis. It also creates a Spark view \"runner\", which is used to apply declarative views of FHIR in Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc707c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from sqlalchemy import dialects\n",
    "from sqlalchemy import engine\n",
    "\n",
    "from google.fhir.views import r4\n",
    "from google.fhir.views import spark_runner\n",
    "\n",
    "# The Spark dataset containing FHIR data. This may be read-only to the user.\n",
    "fhir_dataset = 'default'\n",
    "\n",
    "# The Spark dataset where we will create views, value sets, and other derived tables\n",
    "# as needed. This must be writeable by the user. This will use the default project\n",
    "# where this notebook is running.\n",
    "analysis_dataset = 'statin_analysis_example'\n",
    "\n",
    "dialects.registry.register('hive', 'pyhive.sqlalchemy_hive', 'HiveDialect')\n",
    "\n",
    "# The endpoint of the Hive ThriftServer to connect to\n",
    "query_engine = engine.create_engine('hive://localhost:10001/default')\n",
    "\n",
    "# Create a runner to execute the views over Spark.\n",
    "runner = spark_runner.SparkRunner(\n",
    "    query_engine=query_engine,\n",
    "    fhir_dataset=fhir_dataset,\n",
    "    view_dataset=analysis_dataset,\n",
    "    snake_case_resource_tables=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672a991",
   "metadata": {},
   "source": [
    "## 3. Create tables from the generated parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde3fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with query_engine.connect() as curs:\n",
    "  curs.execute(f'DROP TABLE IF EXISTS {fhir_dataset}.questionnaire_response;')\n",
    "\n",
    "  curs.execute(\n",
    "      f'CREATE TABLE IF NOT EXISTS {fhir_dataset}.questionnaire_response USING PARQUET'\n",
    "      f\" LOCATION '/dwh/controller_DWH_TIMESTAMP_2023_07_19T15_00_27_224851400Z/QuestionnaireResponse/*';\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad1925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with query_engine.connect() as curs:\n",
    "  curs.execute(f'DROP TABLE IF EXISTS {fhir_dataset}.observation;')  \n",
    "  curs.execute(f'DROP TABLE IF EXISTS {fhir_dataset}.immunization;')\n",
    "  curs.execute(f'DROP TABLE IF EXISTS {fhir_dataset}.encounter;')\n",
    "\n",
    "\n",
    "  curs.execute(\n",
    "      f'CREATE TABLE IF NOT EXISTS {fhir_dataset}.observation USING PARQUET'\n",
    "      f\" LOCATION '/dwh/controller_DWH_TIMESTAMP_2023_07_07T10_38_24_324267300Z/Observation*';\"\n",
    "  )\n",
    "  curs.execute(\n",
    "      f'CREATE TABLE IF NOT EXISTS {fhir_dataset}.immunization USING PARQUET'\n",
    "      f\" LOCATION '/dwh/controller_DWH_TIMESTAMP_2023_07_07T10_38_24_324267300Z/Immunization*';\"\n",
    "  )\n",
    "  curs.execute(\n",
    "      f'CREATE TABLE IF NOT EXISTS {fhir_dataset}.encounter USING PARQUET'\n",
    "      f\" LOCATION '/dwh/controller_DWH_TIMESTAMP_2023_07_07T10_38_24_324267300Z/Encounter*';\"\n",
    "  ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a306e53",
   "metadata": {},
   "source": [
    "## 4. Transform a column of items from a QuestionnaireResponse into separate columns in a   tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1481ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define your database connection string\n",
    "db_connection_string = \"hive://localhost:10001/default\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# Define the query using triple quotes\n",
    "query = '''\n",
    "SELECT QR.id as qr_id,QR.encounter['encounterId'],\n",
    "  FIRST(QR.questionnaire, true) AS questionnaire,\n",
    "  FIRST((CASE item_1.linkId WHEN '1.0' THEN item_1.answer[0].value.coding.code ELSE NULL END), true) AS answer_1_1,\n",
    "  FIRST((CASE item_2.linkId WHEN '2.2' THEN item_2.answer[0].value.dateTime ELSE NULL END), true) AS birth_time,\n",
    "  FIRST((CASE item_3.linkId WHEN '3.1.1' THEN item_3.answer[0].value.decimal ELSE NULL END), true) AS birth_weight\n",
    "FROM questionnaire_response AS QR\n",
    "  LATERAL VIEW OUTER EXPLODE(QR.item) AS item_1\n",
    "  LATERAL VIEW OUTER EXPLODE(item_1.item) AS item_2\n",
    "  LATERAL VIEW OUTER EXPLODE(item_2.item) AS item_3\n",
    " GROUP BY QR.id, QR.encounter['encounterId'] ;\n",
    "'''\n",
    "\n",
    "# Use Pandas to read the query result into a DataFrame\n",
    "questionnaireResponse_df = pd.read_sql_query(query, con=engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375364b0",
   "metadata": {},
   "source": [
    "## 5.  Creating views of FHIR resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076ca8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load views based on the base FHIR R4 profile definitions.\n",
    "views = r4.base_r4()\n",
    "\n",
    "obs = views.view_of('Observation')\n",
    "enr = views.view_of('Encounter')\n",
    "imn = views.view_of('Immunization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e7187",
   "metadata": {},
   "source": [
    "## 6.  Creating FHIRPath expressions to select specific items from FHIR resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7fa3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df = runner.to_dataframe(\n",
    "    obs.select(\n",
    "        {\n",
    "            \"ob_id\": obs.id,\n",
    "            \"ob_tag_code\": obs.meta.tag.code,\n",
    "            \"ob_coding_code\":obs.code.coding.code,\n",
    "            \"ob_coding_display\":obs.code.coding.display,\n",
    "            \"ob_subject_ref\": obs.subject.reference,\n",
    "            \"ob_encounter_ref\": obs.encounter.reference,\n",
    "            \"ob_performer_ref\": obs.performer.reference,\n",
    "            \"ob_value\": obs.valueString,\n",
    "            \"ob_valueCodeableConcept\": obs.valueCodeableConcept.coding.code,\n",
    "            \"ob_lastUpdated\": obs.meta.lastUpdated\n",
    "        }\n",
    "    )\n",
    ")\n",
    "observation_df['ob_subject_ref'] = observation_df['ob_subject_ref'].apply(lambda x: x.split('/')[-1] if x else None)\n",
    "observation_df['ob_encounter_ref'] = observation_df['ob_encounter_ref'].apply(lambda x: x.split('/')[-1] if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf21904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "encounter_df = runner.to_dataframe(\n",
    "    enr.select(\n",
    "        {\n",
    "            \"en_id\": enr.id,\n",
    "            \"en_tag_code\": enr.meta.tag.code,\n",
    "            \"en_subject_ref\":enr.subject.reference,\n",
    "            \"en_start\": enr.period.start,\n",
    "            \"en_end\": enr.period.end,\n",
    "            \"en_serviceProv_ref\":enr.serviceProvider.reference,\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d02a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "immunization_df = runner.to_dataframe(\n",
    "    imn.select(\n",
    "        {\n",
    "            \"im_id\": imn.id,\n",
    "            \"im_tag_code\": imn.meta.tag.code,\n",
    "            \"im_status\": imn.status,\n",
    "            \"im_coding_code\":imn.vaccineCode.coding.code,\n",
    "            \"im_coding_display\":imn.vaccineCode.coding.display,\n",
    "            \"im_subject_ref\": imn.patient.reference,\n",
    "            \"im_encounter_ref\": imn.encounter.reference,\n",
    "            \"im_performer_ref\": imn.performer.actor.reference,\n",
    "            \"im_lastUpdated\": imn.meta.lastUpdated\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Extract only the identifier value from the im_subject_ref column\n",
    "immunization_df['im_subject_ref'] = immunization_df['im_subject_ref'].apply(lambda x: x.split('/')[-1] if x else None)\n",
    "immunization_df['im_encounter_ref'] = immunization_df['im_encounter_ref'].apply(lambda x: x.split('/')[-1] if x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86675de",
   "metadata": {},
   "source": [
    "## 7. Filter Encounter resources based on start and end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005c27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Convert start column to datetime64[ns]\n",
    "encounter_df['en_start'] = pd.to_datetime(encounter_df['en_start'])\n",
    "encounter_df['en_end'] = pd.to_datetime(encounter_df['en_end'])\n",
    "\n",
    "\n",
    "# Filter for records between the dates 2022-09-14 and 2022-09-20\n",
    "# filtered_df = encounter_df[\n",
    "#     (encounter_df['en_start'] >= pd.to_datetime(datetime.date(2022, 9, 14))) &\n",
    "#     (encounter_df['en_end'] <= pd.to_datetime(datetime.date(2022, 9, 20)))\n",
    "# ]\n",
    "\n",
    "filtered_df = encounter_df[\n",
    "    (encounter_df['en_start'] >= pd.to_datetime(datetime.date(2022, 9, 14))) &\n",
    "    (encounter_df['en_end'] >= pd.to_datetime(datetime.date(2022, 9, 14))) &\n",
    "    (encounter_df['en_end'] <= pd.to_datetime(datetime.date(2022, 9, 20) + pd.DateOffset(days=1)))  # Add 1 day to include the end date\n",
    "]\n",
    "\n",
    "# Set the display option to show complete data\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211765c2",
   "metadata": {},
   "source": [
    "## 8. Joining Dataframes (Observation,Immunization,QuestionnaireResponse) with Encounter using Left Join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea37a784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform left join between filtered_df and observation_df\n",
    "merged_with_observation_df = pd.merge(filtered_df, observation_df, left_on='en_id', right_on='ob_encounter_ref', how='left')\n",
    "\n",
    "# Perform left join between merged_df and immunization_df\n",
    "merged_with_immunization_df = pd.merge(merged_with_observation_df, immunization_df, left_on='en_id', \n",
    "                                       right_on='im_encounter_ref', how='left')\n",
    "\n",
    "\n",
    "merged_with_questionnaireResponse_df = pd.merge(merged_with_immunization_df, questionnaireResponse_df, \n",
    "                                                left_on='en_id', right_on='encounterId', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Set the display option to show complete data\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb36ed",
   "metadata": {},
   "source": [
    "## Sample JSON Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    " [\n",
    " {\n",
    "    \"id\": 1,\n",
    "    \"categoryId\": \"antenatal\",\n",
    "    \"name\": \"Malaria Tests Positive\",\n",
    "    \"description\": \"No. of Malaria test positive\",\n",
    "    \"redYellow\": \"2\",\n",
    "    \"yellowGreen\": \"5\",\n",
    "    \"fhirPath\": {\n",
    "      \"expression\": \"(ob_coding_code == '[\\\"B54\\\"]') & (ob_valueCodeableConcept == '[\\\"positive\\\"]') | \n",
    "        (ob_value == 'positive')\"\n",
    "    }\n",
    "  },  \n",
    "  {\n",
    "    \"id\": 2,\n",
    "    \"categoryId\": \"antenatal\",\n",
    "    \"name\": \"Malaria Tests Done\",\n",
    "    \"description\": \"No. of Malaria test done\",\n",
    "    \"redYellow\": \"2\",\n",
    "    \"yellowGreen\": \"5\",\n",
    "    \"fhirPath\": {\n",
    "      \"expression\":  \"(ob_coding_code == '[\\\"B54\\\"]') & (ob_valueCodeableConcept == '[\\\"positive\\\"]') | \n",
    "        (ob_value == 'positive') + (ob_coding_code == '[\\\"B54\\\"]') & (ob_valueCodeableConcept == '[\\\"negative\\\"]') \n",
    "        | (ob_value == 'negative') + (ob_coding_code == '[\\\"B54\\\"]') & (ob_valueCodeableConcept == '[\\\"invalid\\\"]') \n",
    "        | (ob_value == 'invalid')\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3,\n",
    "    \"categoryId\": \"labour-and-delivery\",\n",
    "    \"name\": \"Newborn Deaths\",\n",
    "    \"description\": \"Newborn babies death\",\n",
    "    \"redYellow\": \"!1\",\n",
    "    \"yellowGreen\": \"!0\",\n",
    "    \"fhirPath\": {\n",
    "      \"expression\": \"(ob_coding_code == '[\\\"IPRD.DE67\\\"]')\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"categoryId\": \"child-growth-monitoring\",\n",
    "    \"name\": \"Number of Children growth monitored\",\n",
    "    \"description\": \"No. of Child growth monitored\",\n",
    "    \"redYellow\": \"2\",\n",
    "    \"yellowGreen\": \"5\",\n",
    "    \"fhirPath\": {\n",
    "      \"expression\":  \"(ob_coding_code == '[\\\"IPRD.DE63\\\"]')\"\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8c518",
   "metadata": {},
   "source": [
    "## 9. Loading JSON data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bbff51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"C:/Repos/fhir-data-pipes/docker/dwh/controller_DWH_TIMESTAMP_2023_07_19T15_00_27_224851400Z/definitions.json\"\n",
    "# Open the file and load its contents\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94d250",
   "metadata": {},
   "source": [
    "## 10. Running expressions in the flattened table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1111a7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malaria Tests Positive : 26\n",
      "Malaria Tests Done : 52\n",
      "Newborn Deaths : 0\n",
      "Number of Children growth monitored : 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import pandas if not already imported\n",
    "import re\n",
    "\n",
    "# # Load your DataFrame or create df_for_observation\n",
    "df_for_observation = merged_with_questionnaireResponse_df.drop_duplicates(subset=['ob_id'])\n",
    "\n",
    "# # Assuming your JSON data is loaded in the 'data' variable\n",
    "\n",
    "# # Extract the expression from the JSON\n",
    "# expression = data[0][\"fhirPath\"][\"expression\"]\n",
    "\n",
    "\n",
    "\n",
    "for defn in data:\n",
    "    expression = defn[\"fhirPath\"][\"expression\"]\n",
    "    if '+' in expression:\n",
    "        split_expressions = [expr.strip() for expr in re.split(r'\\s*\\+\\s*', expression)]\n",
    "        total_sum = 0\n",
    "        for exp in split_expressions:\n",
    "            filtered_df = df_for_observation.eval(exp)\n",
    "            total_sum += filtered_df.sum()\n",
    "            filtered_df = pd.DataFrame()\n",
    "        print(defn[\"name\"],\":\",total_sum)    \n",
    "    else:\n",
    "        filtered_df = df_for_observation.eval(expression)\n",
    "        print(defn[\"name\"],\":\",filtered_df.sum())\n",
    "\n",
    "    \n",
    "\n",
    "# Evaluate the expression on df_for_observation\n",
    "# filtered_df = df_for_observation.eval(expression)\n",
    "\n",
    "# print(\"malaria positive count is\", filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d61d5",
   "metadata": {},
   "source": [
    "## Exporting Dataframes to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "56f3dc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\developer\\\\Downloads\\\\obs.csv'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Keep only unique rows based on 'ob_id'\n",
    "# final_df_unique = final_df.drop_duplicates(subset='ob_id')\n",
    "df_for_observation = merged_with_questionnaireResponse_df.drop_duplicates(subset=['ob_id'])\n",
    "# Save the DataFrame as CSV\n",
    "df_for_observation.to_csv('obs.csv', index=False)\n",
    "\n",
    "# Specify the download path\n",
    "download_path = 'C:\\\\Users\\\\developer\\\\Downloads\\\\obs.csv'\n",
    "\n",
    "# Move the CSV file to the download path\n",
    "shutil.move('obs.csv', download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9709d7b",
   "metadata": {},
   "source": [
    "## Running expressions in the flattened table manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09f05d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newborn_deaths :  0\n",
      "malaria tests done:  52\n",
      "malaria positive:  26\n",
      "child growth monitored:  0\n"
     ]
    }
   ],
   "source": [
    "df_for_observation = merged_with_questionnaireResponse_df.drop_duplicates(subset=['ob_id'])\n",
    "\n",
    "filtered_df = df_for_observation[df_for_observation[\"ob_coding_code\"] == '[\"IPRD.DE67\"]']\n",
    "count_result = filtered_df.shape[0]\n",
    "print(\"newborn_deaths : \", count_result)\n",
    "\n",
    "\n",
    "mpt_df = df_for_observation[(df_for_observation[\"ob_coding_code\"] == '[\"B54\"]') & (df_for_observation[\"ob_valueCodeableConcept\"] == '[\"positive\"]') | (df_for_observation[\"ob_value\"] == 'positive')] \n",
    "mnt_df = df_for_observation[(df_for_observation[\"ob_coding_code\"] == '[\"B54\"]') & (df_for_observation[\"ob_valueCodeableConcept\"] == '[\"negative\"]') | (df_for_observation[\"ob_value\"] == 'negative')]\n",
    "mivd_df =  df_for_observation[(df_for_observation[\"ob_coding_code\"] == '[\"B54\"]') & (df_for_observation[\"ob_valueCodeableConcept\"] == '[\"invalid\"]') | (df_for_observation[\"ob_value\"] == 'invalid')]\n",
    "\n",
    "count_result = mpt_df.shape[0] + mnt_df.shape[0] + mivd_df.shape[0]\n",
    "print(\"malaria tests done: \", count_result)\n",
    "print(\"malaria positive: \", mpt_df.shape[0])\n",
    "\n",
    "childgrowth_df = df_for_observation[df_for_observation[\"ob_coding_code\"] == '[\"IPRD.DE63\"]']\n",
    "print(\"child growth monitored: \", childgrowth_df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0498b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routineImmunization: 0\n"
     ]
    }
   ],
   "source": [
    "df_for_immunization = merged_with_questionnaireResponse_df.drop_duplicates(subset=['im_id'])\n",
    "\n",
    "# Filter out rows with missing values in the \"im_coding_display\" column\n",
    "df_for_immunization_filtered = df_for_immunization.dropna(subset=['im_coding_display'])\n",
    "\n",
    "# Use str.contains on the filtered DataFrame\n",
    "routineImmunization = df_for_immunization_filtered[df_for_immunization_filtered[\"im_coding_display\"].str.contains('routine-immunization')]\n",
    "print(\"routineImmunization:\", routineImmunization.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2d84f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postnatal Mother Care:  0\n",
      "Postnatal Baby Care:  0\n",
      "Antenatal Care:  58\n",
      "Newborns Registered: 0\n"
     ]
    }
   ],
   "source": [
    "df_for_questionnaireResponse = merged_with_questionnaireResponse_df.drop_duplicates(subset=['qr_id'])\n",
    "\n",
    "postnatalMotherCare = df_for_questionnaireResponse[df_for_questionnaireResponse[\"questionnaire\"] == \"Questionnaire/post-natal-mother\"].drop_duplicates(subset=['encounterId'])\n",
    "print(\"Postnatal Mother Care: \", postnatalMotherCare.shape[0])\n",
    "\n",
    "postnatalBabyCare =  df_for_questionnaireResponse[df_for_questionnaireResponse[\"questionnaire\"] == \"Questionnaire/post-natal-baby\"].drop_duplicates(subset=['encounterId'])\n",
    "print(\"Postnatal Baby Care: \", postnatalBabyCare.shape[0])\n",
    "\n",
    "antenatalCare = (\n",
    "    df_for_questionnaireResponse[df_for_questionnaireResponse[\"questionnaire\"] == \"Questionnaire/anc-visit\"].drop_duplicates(subset=['encounterId']).shape[0] +\n",
    "    df_for_questionnaireResponse[df_for_questionnaireResponse[\"questionnaire\"] == \"Questionnaire/anc-visit-v1\"].drop_duplicates(subset=['encounterId']).shape[0] +\n",
    "    df_for_questionnaireResponse[df_for_questionnaireResponse[\"questionnaire\"] == \"Questionnaire/vitals\"].drop_duplicates(subset=['encounterId']).shape[0]\n",
    ")\n",
    "print(\"Antenatal Care: \", antenatalCare)\n",
    "\n",
    "newbornRegistered = df_for_questionnaireResponse[\n",
    "    (df_for_questionnaireResponse[\"questionnaire\"] == \"Questionnaire/delivery\") &\n",
    "    (df_for_questionnaireResponse[\"answer_1_1\"] == 'live-birth')\n",
    "]\n",
    "\n",
    "print(\"Newborns Registered:\", newbornRegistered.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
